{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 지도학습 절차\n",
        "\n",
        "- 지도학습 : 목표변수(Y)와 설명변수(X)의 관계를 학습해서, 새로운 X가 들어올 때, Y를 예측 / 분류\n",
        "\n",
        "- 지도학습의 절차 6단계:\n",
        "  1. 데이터 핸들링 (데이터 불러오기 / 파생변수 생성 / 층별화) : 데이터 구조적인 관점에서 학습을 수행할 수 있는 데이터셋을 구성하는 과정\n",
        "\n",
        "  2. 학습에 사용될 목표변수(Y)와 설명변수(X)를 설정\n",
        "    - 유의사항 : 사용되는 X는 새로 들어올 데이터에 대한 값으로 지정 ex. 신규고객 이탈 예측을 할 때 구매횟수와 방문횟수를 넣으면 안 됨.\n",
        "\n",
        "  3. 학습 데이터(Train Set)와 검증 데이터(Test Set)분할\n",
        "    - 검증 데이터(Test Set)는 학습에 참여하지 않는다! (교차검증에서 Validation Set과는 다른 개념)\n",
        "\n",
        "  4. 학습을 수행 (Modeling)\n",
        "    - 특성공학 (결측값 처리 / Encoding / Scaling ...) -> Pipe Line을 이용해서\n",
        "    - 학습 (알고리즘)\n",
        "\n",
        "  5. 학습된 모델 평가\n",
        "    - 학습 능력 평가\n",
        "    - 일반화 능력 평가\n",
        "\n",
        "  6. 새로운 데이터를 적용\n",
        "    - 학습된 모델을 파일형태로 추출 -> Web, App, System에 넣을 수 있는 형태로 저장"
      ],
      "metadata": {
        "id": "JwHfbG5eF_pj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xtbzlftIGBLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 사용한 데이터 (https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)"
      ],
      "metadata": {
        "id": "mIuV8FMpGBqD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bst0RcZHGEkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 과적합(Overfitting)\n",
        "\n",
        "- 과적합 : 학습 데이터에 대해서는 Model이 높은 성능을 나타내지만, 검증데이터에서는 성능이 낮게 나오는 현상\n",
        "- 해결 : 특성공학을 통해 데이터를 더 깔끔하게 생성\n",
        "\n",
        "\n",
        "### 특성공학(Feature Engineering)\n",
        "- **특성공학** : 학습의 목적에 맞게(학습이 잘 수행될 수 있도록) 데이터를 깔끔하게 다듬는 작업\n",
        "- 대표적 기법 :\n",
        "  1. Scaling & Encoding : 숫자 데이터의 스케일을 맞추거나, 문자 데이터를 숫자로 변환하여 학습에 사용\n",
        "  2. Imputation : 데이터 상에 존재하는 결측값에 대해 다른 값으로 대치 (새로 들어오는 데이터가 결측일 수도 있기 때문에)\n",
        "  3. Cross Validation (교차검증): 학습데이터를 여러 단계로 나누어 분할하여 학습\n",
        "  4. Hyper Parameter Tuning : 학습 알고리즘 내 존재하는 수학적 구조나 학습에 발생하는 구조, 함수들을 사용자가 통제\n",
        "  5. Imbalanced Data Sampling : 목표변수의 비율이 깨져있는 데이터를 맞추어 학습\n",
        "  6. Feature Selection : 목표변수에 가장 영향이 있는 인자를 사용자가 지정한 만큼 선택해서 학습\n",
        "  7. PCA : 데이터의 차원을 줄이거나 특성을 재구성하여 학습\n",
        "\n",
        "- Scikit Learn에서 특성공학 기법과 학습을 동시에 수행할 수 있게 Pipe Line 구성하여 학습을 수행"
      ],
      "metadata": {
        "id": "GJ0I7swFGFEC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9P1IarOGPFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 의사결정나무의 하이퍼파라미터\n",
        "- criterion : 분할 기준\n",
        "- max_depth : 트리의 최대 깊이(너무 깊으면 과적합 발생 가능)\n",
        "- min_samples_split : 노드 분할을 위한 최소 샘플 수\n",
        "- max_leaf_nodes : 리프 노드의 최대 개수\n",
        "- ...\n",
        "- => 모델에 따라 하이퍼파라미터가 다름! 또한 너무 많은 튜닝을 해버리면 노트북 자원에 따라 시간이 너무 오래 걸릴 수 있음"
      ],
      "metadata": {
        "id": "aZHTS0K6GPsL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buDZpAUZGXw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **정확도 Accuracy** = 예측결과가 동일한 데이터 수 / 전체 예측 데이터 수\n",
        "  - 클래스가 균형을 이룰 때 사용하는 지표\n",
        "  - 모든 클래스가 동등한 중요도를 가질 때 확인하는 지표(이탈이 더 중요하기 때문에 정확도만을 보고 판단해서는 안됨)\n",
        "  - 목표변수(Y)가 불균형한(Imbalanced)데이터인 경우엔 적합한 평가지표로 사용하기 어렵다\n",
        "\n",
        "- **오차 행렬 Confusion Matrix**\n",
        "  - **정밀도 Precision**  : TP / (TP + FP)\n",
        "    - 예측을 Positive로 한 대상 중, 예측값과 실제값이 Positive로 일치한 데이터의 비율\n",
        "    - 문제가 없는 데이터를 문제가 있다고 잘못 판단할 때 발생하는 이슈를 나타내는 지표(중요한 메일이 스팸으로 분류되는 경우)\n",
        "    - False Positive를 낮추는 데 초점 / 예 - 스팸메시지 분류기\n",
        "\n",
        "  - **재현율 Recall** : TP / (TP + FN)\n",
        "    - 실제값이 Positive인 대상 중 예측값과 실제값이 Positive로 일치하는 데이터의 비율\n",
        "    - 민감도 (Sensitivity) 또는 TPR (True Positive Rate)로 불림\n",
        "    - 실제 문제가 있는 데이터를 문제가 없다고 잘못 판단할 때 발생하는 이슈를 나타내는 지표\n",
        "    - False Negative를 낮추는 데 초점 / 예 - 암 진단 (실제로 암인데, 정상으로 분류하는 경우)\n",
        "    - 이탈 고객인데, 정상 고객으로 분류하는 경우\n",
        "\n",
        "  - **F1-Score** : 2 x 정밀도 x 재현율 / (정밀도 + 재현율)\n",
        "    - 정밀도와 재현율이 균형이 필요한 경우에 사용\n",
        "    - 정밀도와 재현율 둘 다 한쪽으로 치우치지 않을 때, 높은 값을 나타내는 지표"
      ],
      "metadata": {
        "id": "JfPx3UMyGYva"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C3Cv35wXGZL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 과제 2-1. 팀 별로 정해진 모델에 맞게 분류 모델 만들어오기\n",
        "- 모델의 장단점 및 해당 모델에 맞는 특성공학 기법을 정리한 뒤, 해당 모델에 맞는 특성공학 기법을 적용해야 함\n",
        "- 사용할 데이터 : 오늘 수업 때 배운 diabetes.csv\n",
        "- 1조 : 랜덤포레스트, 2조 : Gradient Boosting\n",
        "\n",
        "### 과제 2-2. (기본) 5. 회귀모델 만들기 예습"
      ],
      "metadata": {
        "id": "GWCulcySGahi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdn9N7OlGf3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}